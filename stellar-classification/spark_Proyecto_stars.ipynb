{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c38b63ad-8c2e-494d-8b42-a426ec98f315",
   "metadata": {},
   "source": [
    "### Stellar Classification Dataset - SDSS17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2b160e",
   "metadata": {},
   "source": [
    "**1. CARGA DE DATOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e71519e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- obj_ID: double (nullable = true)\n",
      " |-- alpha: double (nullable = true)\n",
      " |-- delta: double (nullable = true)\n",
      " |-- u: double (nullable = true)\n",
      " |-- g: double (nullable = true)\n",
      " |-- r: double (nullable = true)\n",
      " |-- i: double (nullable = true)\n",
      " |-- z: double (nullable = true)\n",
      " |-- run_ID: integer (nullable = true)\n",
      " |-- rerun_ID: integer (nullable = true)\n",
      " |-- cam_col: integer (nullable = true)\n",
      " |-- field_ID: integer (nullable = true)\n",
      " |-- spec_obj_ID: double (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- redshift: double (nullable = true)\n",
      " |-- plate: integer (nullable = true)\n",
      " |-- MJD: integer (nullable = true)\n",
      " |-- fiber_ID: integer (nullable = true)\n",
      "\n",
      "+--------------------+----------------+------------------+--------+--------+--------+--------+--------+------+--------+-------+--------+--------------------+------+---------+-----+-----+--------+\n",
      "|              obj_ID|           alpha|             delta|       u|       g|       r|       i|       z|run_ID|rerun_ID|cam_col|field_ID|         spec_obj_ID| class| redshift|plate|  MJD|fiber_ID|\n",
      "+--------------------+----------------+------------------+--------+--------+--------+--------+--------+------+--------+-------+--------+--------------------+------+---------+-----+-----+--------+\n",
      "|1.237660961327743...|  135.6891066036|  32.4946318397087|23.87882| 22.2753|20.39501|19.16573|18.79371|  3606|     301|      2|      79|6.543777369295181...|GALAXY|0.6347936| 5812|56354|     171|\n",
      "|1.237664879951151...|144.826100550256|  31.2741848944939|24.77759|22.83188|22.58444|21.16812|21.61427|  4518|     301|      5|     119|1.176014203670733...|GALAXY| 0.779136|10445|58158|     427|\n",
      "|1.237660961330430...|142.188789562506|  35.5824441819976|25.26307|22.66389|20.60976|19.34857|18.94827|  3606|     301|      2|     120|5.152200256025548...|GALAXY|0.6441945| 4576|55592|     299|\n",
      "|1.237663478724297...|338.741037753146|-0.402827574587482|22.13682|23.77656|21.61162|20.50454| 19.2501|  4192|     301|      3|     214|1.030107141295442...|GALAXY|0.9323456| 9149|58039|     775|\n",
      "|1.237680272041378...|345.282593210935|  21.1838656010284|19.43718|17.58028|16.49747|15.97711|15.54461|  8102|     301|      3|     137|6.891864880783317E18|GALAXY|0.1161227| 6121|56187|     842|\n",
      "+--------------------+----------------+------------------+--------+--------+--------+--------+--------+------+--------+-------+--------+--------------------+------+---------+-----+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crear una instancia de SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Cargar el dataset como DataFrame\n",
    "df = spark.read.csv(r\"file:///home/jovyan/work/star_classification.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# estructura del DataFrame\n",
    "df.printSchema()\n",
    "\n",
    "# 5 primeras filas\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2229b6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas:  100000\n",
      "Número de columnas:  18\n"
     ]
    }
   ],
   "source": [
    "# numero de filas\n",
    "num_rows = df.count()\n",
    "\n",
    "# numero de columnas\n",
    "num_columns = len(df.columns)\n",
    "\n",
    "print(\"Número de filas: \", num_rows)\n",
    "print(\"Número de columnas: \", num_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b0cb76-38db-49af-86ea-12f7f4c65256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores unicos de la columna class\n",
    "class_values = df.select(\"class\").distinct()\n",
    "\n",
    "print(\"Valores de la columna 'class': \")\n",
    "class_values.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3197acb4",
   "metadata": {},
   "source": [
    "**2. Limpieza de valores nulos:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a1a07-6555-41e3-bf2f-f4924668f3b0",
   "metadata": {},
   "source": [
    "Se utiliza una expresión lambda con la función select() para aplicar sum(col(column).isNull().cast(\"int\")) a cada columna del DataFrame. \n",
    "Esto cuenta el número de valores nulos en cada columna y asigna el nombre de la columna a través de alias(column). \n",
    "Luego utilizamos show() para mostrar el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4655ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+---+---+---+---+---+------+--------+-------+--------+-----------+-----+--------+-----+---+--------+\n",
      "|obj_ID|alpha|delta|  u|  g|  r|  i|  z|run_ID|rerun_ID|cam_col|field_ID|spec_obj_ID|class|redshift|plate|MJD|fiber_ID|\n",
      "+------+-----+-----+---+---+---+---+---+------+--------+-------+--------+-----------+-----+--------+-----+---+--------+\n",
      "|     0|    0|    0|  0|  0|  0|  0|  0|     0|       0|      0|       0|          0|    0|       0|    0|  0|       0|\n",
      "+------+-----+-----+---+---+---+---+---+------+--------+-------+--------+-----------+-----+--------+-----+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "# numero total de nulos por columna\n",
    "null_counts = df.select([sum(col(column).isNull().cast(\"int\")).alias(column) for column in df.columns])\n",
    "null_counts.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8dff64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar filas con valores faltantes en cualquier columna\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4370e40a-0484-4f33-a5c7-2bb3eeb1f7d3",
   "metadata": {},
   "source": [
    "**3. Limpieza de valores duplicados:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38cba4b1-8d08-482b-bbad-3d27e5b1701a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas totales en el DataFrame: 100000\n",
      "Filas únicas en el DataFrame: 100000\n",
      "No hay duplicados en el DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# numero total de filas en el DataFrame\n",
    "total_rows = df.count()\n",
    "print(f\"Filas totales en el DataFrame: {total_rows}\")\n",
    "\n",
    "# numero de filas despues de eliminar los duplicados\n",
    "unique_rows = df.dropDuplicates().count()\n",
    "print(f\"Filas únicas en el DataFrame: {unique_rows}\")\n",
    "\n",
    "# verificar si hay datos duplicados\n",
    "if total_rows == unique_rows:\n",
    "    print(\"No hay duplicados en el DataFrame.\")\n",
    "else:\n",
    "    print(f\"Hay {total_rows-unique_rows} duplicados en el DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c65bf574-b20d-4717-8b4b-0d23f611433f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+---+---+---+---+---+------+--------+-------+--------+-----------+-----+--------+-----+---+--------+\n",
      "|obj_ID|alpha|delta|  u|  g|  r|  i|  z|run_ID|rerun_ID|cam_col|field_ID|spec_obj_ID|class|redshift|plate|MJD|fiber_ID|\n",
      "+------+-----+-----+---+---+---+---+---+------+--------+-------+--------+-----------+-----+--------+-----+---+--------+\n",
      "+------+-----+-----+---+---+---+---+---+------+--------+-------+--------+-----------+-----+--------+-----+---+--------+\n",
      "\n",
      "Hay 0 filas duplicadas en el DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# se muestran los datos duplicados\n",
    "duplicated_data = df.exceptAll(df.dropDuplicates())\n",
    "duplicated_data.show()\n",
    "\n",
    "print(f\"Hay {total_rows-unique_rows} filas duplicadas en el DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a59510e9-7abc-414e-9414-c1b6f869f002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de la columna 'class': \n",
      "+------+\n",
      "| class|\n",
      "+------+\n",
      "|GALAXY|\n",
      "|   QSO|\n",
      "|  STAR|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# valores unicos de la columna class\n",
    "class_values = df.select(\"class\").distinct()\n",
    "\n",
    "print(\"Valores de la columna 'class': \")\n",
    "class_values.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ed015d-72f7-4f87-a015-93b36fb31733",
   "metadata": {},
   "source": [
    "**Antes de ejecutar la siguiente celda que se conecta a MySQL y crea la tabla e inserta los 100.000 registros, es necesario crear un nuevo usuario (\"user1\") en MySQL.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0a568c-4dbd-4fd7-bd3c-cac9b3d15ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell takes 1-2mins\n",
    "url =\"jdbc:mysql://192.168.1.42:3306/stellar_class\"\n",
    "tabla_stars = \"stars\"\n",
    "propiedades = { \n",
    "    \"user\": \"user1\",\n",
    "    \"password\": \"abc123.\",\n",
    "    \"driver\": \"com.mysql.jdbc.Driver\"\n",
    "}\n",
    "\n",
    "df.select(\"obj_ID\",\"alpha\",\"delta\",\"u\",\"g\",\"r\",\"i\",\"z\",\"run_ID\",\"rerun_ID\",\"cam_col\",\"field_ID\",\"spec_obj_ID\",\"class\",\"redshift\",\"plate\",\"MJD\",\"fiber_ID\").write.format(\"jdbc\").option(\"url\", url).option(\"dbtable\", tabla_stars).option(\"user\", propiedades[\"user\"]).option(\"password\", propiedades[\"password\"]).option(\"driver\", propiedades[\"driver\"]).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56395679-72e4-4815-b14b-779e9dcb88c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9add52de-0e7a-4a45-8689-084a6153dc78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
